{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from resources.workspace import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "%MACRO DEFINITION\n",
    "\\newcommand{\\Reals}{\\mathbb{R}}\n",
    "\\newcommand{\\Imags}{i\\Reals}\n",
    "\\newcommand{\\Integers}{\\mathbb{Z}}\n",
    "\\newcommand{\\Naturals}{\\mathbb{N}}\n",
    "%\n",
    "\\newcommand{\\Expect}[0]{\\mathop{}\\! \\mathbb{E}}\n",
    "\\newcommand{\\NormDist}{\\mathop{}\\! \\mathcal{N}}\n",
    "%\n",
    "\\newcommand{\\mat}[1]{{\\mathbf{{#1}}}} \n",
    "%\\newcommand{\\mat}[1]{{\\pmb{\\mathsf{#1}}}}\n",
    "\\newcommand{\\bvec}[1]{{\\mathbf{#1}}}\n",
    "%\n",
    "\\newcommand{\\trsign}{{\\mathsf{T}}}\n",
    "\\newcommand{\\tr}{^{\\trsign}}\n",
    "%\n",
    "\\newcommand{\\I}[0]{\\mat{I}}\n",
    "\\newcommand{\\K}[0]{\\mat{K}}\n",
    "\\newcommand{\\bP}[0]{\\mat{P}}\n",
    "\\newcommand{\\F}[0]{\\mat{F}}\n",
    "\\newcommand{\\bH}[0]{\\mat{H}}\n",
    "\\newcommand{\\bF}[0]{\\mat{F}}\n",
    "\\newcommand{\\R}[0]{\\mat{R}}\n",
    "\\newcommand{\\Q}[0]{\\mat{Q}}\n",
    "\\newcommand{\\B}[0]{\\mat{B}}\n",
    "\\newcommand{\\Ri}[0]{\\R^{-1}}\n",
    "\\newcommand{\\Bi}[0]{\\B^{-1}}\n",
    "\\newcommand{\\X}[0]{\\mat{X}}\n",
    "\\newcommand{\\A}[0]{\\mat{A}}\n",
    "\\newcommand{\\Y}[0]{\\mat{Y}}\n",
    "\\newcommand{\\E}[0]{\\mat{E}}\n",
    "\\newcommand{\\U}[0]{\\mat{U}}\n",
    "\\newcommand{\\V}[0]{\\mat{V}}\n",
    "%\n",
    "\\newcommand{\\x}[0]{\\bvec{x}}\n",
    "\\newcommand{\\y}[0]{\\bvec{y}}\n",
    "\\newcommand{\\br}[0]{\\bvec{r}}\n",
    "\\newcommand{\\bb}[0]{\\bvec{b}}\n",
    "%\n",
    "\\newcommand{\\cx}[0]{\\text{const}}\n",
    "\\newcommand{\\norm}[1]{\\|{#1}\\|}\n",
    "%\n",
    "$Similarly\n",
    "\n",
    "In this tutorial we shall derive:\n",
    "\n",
    "# the Kalman filter for multivariate systems.  \n",
    "\n",
    "The [forecast step](T3%20-%20Univariate%20Kalman%20filtering.ipynb#The-forecast-step) remains essentially unchanged. The only difference is the use of the transpose ${}^T$ in the covariance equation:\n",
    "$\\begin{align}\n",
    "\\mathbf{\\hat{x}}_k^f\n",
    "&= \\bF_{k-1} \\mathbf{\\hat{\\x}}_{k-1}^a \\, , \\tag{1a} \\\\\\\n",
    "\\mathbf{P}_k^f\n",
    "&= \\bF_{k-1} \\bP_{k-1}^a \\bF_{k-1}^T + \\Q_{k-1} \\, . \\tag{1b}\n",
    "\\end{align}$\n",
    "\n",
    "However, the *analysis step* gets a little more complicated.\n",
    "\n",
    "#### Exc 2 (The likelihood):\n",
    "Suppose the observations at time $k$ is related to the true state ($\\x_k$) by:\n",
    "\\begin{align*}\n",
    "\\y_k &= \\bH \\x_k + \\br_k \\, , \\;\\; \\qquad (2)\n",
    "\\end{align*}\n",
    "where the noise follows the law $\\br_k \\sim \\NormDist(\\mathbf{0}, \\R_k)$ for some $\\R_k>0$ (i.e. $\\mathbf{R}_k$ is symmetric-positive-definite).\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "<b>NB:</b> The analysis step is only concerned with a single time (index). We therefore drop the $k$ subscript in the following.\n",
    "</div>\n",
    "\n",
    "Derive the expression for $p(\\mathbf{y}|\\mathbf{x})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#show_answer('Likelihood derivation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following exercise derives the analysis step\n",
    "\n",
    "#### Exc 4 (The 'precision' form of the KF):\n",
    "$\n",
    "%MACRO DEFINITION\n",
    "\\newcommand{\\Reals}{\\mathbb{R}}\n",
    "\\newcommand{\\Imags}{i\\Reals}\n",
    "\\newcommand{\\Integers}{\\mathbb{Z}}\n",
    "\\newcommand{\\Naturals}{\\mathbb{N}}\n",
    "%\n",
    "\\newcommand{\\Expect}[0]{\\mathop{}\\! \\mathbb{E}}\n",
    "\\newcommand{\\NormDist}{\\mathop{}\\! \\mathcal{N}}\n",
    "%\n",
    "\\newcommand{\\mat}[1]{{\\mathbf{{#1}}}} \n",
    "%\\newcommand{\\mat}[1]{{\\pmb{\\mathsf{#1}}}}\n",
    "\\newcommand{\\bvec}[1]{{\\mathbf{#1}}}\n",
    "%\n",
    "\\newcommand{\\trsign}{{\\mathsf{T}}}\n",
    "\\newcommand{\\tr}{^{\\trsign}}\n",
    "%\n",
    "\\newcommand{\\I}[0]{\\mat{I}}\n",
    "\\newcommand{\\K}[0]{\\mat{K}}\n",
    "\\newcommand{\\bP}[0]{\\mat{P}}\n",
    "\\newcommand{\\F}[0]{\\mat{F}}\n",
    "\\newcommand{\\bH}[0]{\\mat{H}}\n",
    "\\newcommand{\\bF}[0]{\\mat{F}}\n",
    "\\newcommand{\\R}[0]{\\mat{R}}\n",
    "\\newcommand{\\Q}[0]{\\mat{Q}}\n",
    "\\newcommand{\\B}[0]{\\mat{B}}\n",
    "\\newcommand{\\Ri}[0]{\\R^{-1}}\n",
    "\\newcommand{\\Bi}[0]{\\B^{-1}}\n",
    "\\newcommand{\\X}[0]{\\mat{X}}\n",
    "\\newcommand{\\A}[0]{\\mat{A}}\n",
    "\\newcommand{\\Y}[0]{\\mat{Y}}\n",
    "\\newcommand{\\E}[0]{\\mat{E}}\n",
    "\\newcommand{\\U}[0]{\\mat{U}}\n",
    "\\newcommand{\\V}[0]{\\mat{V}}\n",
    "%\n",
    "\\newcommand{\\x}[0]{\\bvec{x}}\n",
    "\\newcommand{\\y}[0]{\\bvec{y}}\n",
    "\\newcommand{\\br}[0]{\\bvec{r}}\n",
    "\\newcommand{\\bb}[0]{\\bvec{b}}\n",
    "%\n",
    "\\newcommand{\\cx}[0]{\\text{const}}\n",
    "\\newcommand{\\norm}[1]{\\|{#1}\\|}\n",
    "%\n",
    "$Similarly to [Exc 2.18](T2%20-%20Bayesian%20inference.ipynb#Exc--2.18-'Gaussian-Bayes':),\n",
    "it may be shown that the prior $p(\\x) = \\NormDist(\\x \\mid \\bb,\\B)$\n",
    "and likelihood $p(\\y|\\x) = \\NormDist(\\y \\mid \\bH \\x,\\R)$,\n",
    "yield the posterior:\n",
    "\\begin{align}\n",
    "p(\\x|\\y)\n",
    "&= \\NormDist(\\x \\mid \\hat{\\x}, \\bP) \\tag{4}\n",
    "\\, ,\n",
    "\\end{align}\n",
    "where the posterior/analysis mean (vector) and covariance (matrix) are given by:\n",
    "\\begin{align}\n",
    "\t\t\t\\bP &= (\\bH\\tr \\Ri \\bH + \\Bi)^{-1} \\, , \\tag{5} \\\\\n",
    "\t\t\t\\hat{\\x} &= \\bP\\left[\\bH\\tr \\Ri \\y + \\Bi \\bb\\right] \\tag{6}Â \\, ,\n",
    "\\end{align}\n",
    "Prove eqns (4-6).  \n",
    "Hint: as in [Exc 2.18](T2%20-%20Bayesian%20inference.ipynb#Exc--2.18-'Gaussian-Bayes':), the main part lies in \"completing the square\" in $\\x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#show_answer('KF precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "%MACRO DEFINITION\n",
    "\\newcommand{\\Expect}[0]{\\mathop{}\\! \\mathbb{E}}\n",
    "\\newcommand{\\NormDist}{\\mathop{}\\! \\mathcal{N}}\n",
    "%\n",
    "\\newcommand{\\mat}[1]{{\\mathbf{{#1}}}} \n",
    "%\\newcommand{\\mat}[1]{{\\pmb{\\mathsf{#1}}}}\n",
    "\\newcommand{\\bvec}[1]{{\\mathbf{#1}}}\n",
    "%\n",
    "\\newcommand{\\trsign}{{\\mathsf{T}}}\n",
    "\\newcommand{\\tr}{^{\\trsign}}\n",
    "%\n",
    "\\newcommand{\\I}[0]{\\mat{I}}\n",
    "\\newcommand{\\K}[0]{\\mat{K}}\n",
    "\\newcommand{\\bP}[0]{\\mat{P}}\n",
    "\\newcommand{\\F}[0]{\\mat{F}}\n",
    "\\newcommand{\\bH}[0]{\\mat{H}}\n",
    "\\newcommand{\\bF}[0]{\\mat{F}}\n",
    "\\newcommand{\\R}[0]{\\mat{R}}\n",
    "\\newcommand{\\Q}[0]{\\mat{Q}}\n",
    "\\newcommand{\\B}[0]{\\mat{B}}\n",
    "\\newcommand{\\Ri}[0]{\\R^{-1}}\n",
    "\\newcommand{\\Bi}[0]{\\B^{-1}}\n",
    "\\newcommand{\\X}[0]{\\mat{X}}\n",
    "\\newcommand{\\A}[0]{\\mat{A}}\n",
    "\\newcommand{\\Y}[0]{\\mat{Y}}\n",
    "\\newcommand{\\E}[0]{\\mat{E}}\n",
    "\\newcommand{\\U}[0]{\\mat{U}}\n",
    "\\newcommand{\\V}[0]{\\mat{V}}\n",
    "%\n",
    "\\newcommand{\\x}[0]{\\bvec{x}}\n",
    "\\newcommand{\\y}[0]{\\bvec{y}}\n",
    "\\newcommand{\\bb}[0]{\\bvec{b}}\n",
    "%\n",
    "\\newcommand{\\cx}[0]{\\text{const}}\n",
    "\\newcommand{\\norm}[1]{\\|{#1}\\|}\n",
    "%\n",
    "$<div class=\"alert alert-info\" role=\"alert\">\n",
    "We have now derived (one form of) the Kalman filter. In the multivariate case,\n",
    "we know how to:\n",
    "<ul>\n",
    "  <li>Propagate our estimate of $\\x$ to the next time step using eqns (1a) and (1b). </li>\n",
    "  <li>Update our estimate of $\\x$ by assimilating the latest observation $\\y$, using eqns (5) and (6).</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "However, the computations can be pretty expensive..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 5:** Suppose $\\mathbf{x}$ is $M$-dimensional and has a covariance matrix $\\mathbf{B}$.\n",
    " * (a). What's the size of $\\mathbf{B}$?\n",
    " * (b). How many \"flops\" (approximately, i.e. to leading order) are required  \n",
    " to compute the \"precision form\" of the KF update equation, eqn (5) ?\n",
    " * (c). How much memory (bytes) is required to hold its covariance matrix $\\mathbf{B}$ ?\n",
    " * (d). How many mega bytes's is this if $M$ is a million?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#show_answer('Cov memory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one of the principal reasons why basic extended KF is infeasible for DA. \n",
    "The following exercises serve to derive another, often more practical, form of the KF analysis update."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exc 6 (The \"Woodbury\" matrix inversion identity):\n",
    "$\n",
    "%MACRO DEFINITION\n",
    "\\newcommand{\\Expect}[0]{\\mathop{}\\! \\mathbb{E}}\n",
    "\\newcommand{\\NormDist}{\\mathop{}\\! \\mathcal{N}}\n",
    "%\n",
    "\\newcommand{\\mat}[1]{{\\mathbf{{#1}}}} \n",
    "%\\newcommand{\\mat}[1]{{\\pmb{\\mathsf{#1}}}}\n",
    "\\newcommand{\\bvec}[1]{{\\mathbf{#1}}}\n",
    "%\n",
    "\\newcommand{\\trsign}{{\\mathsf{T}}}\n",
    "\\newcommand{\\tr}{^{\\trsign}}\n",
    "%\n",
    "\\newcommand{\\I}[0]{\\mat{I}}\n",
    "\\newcommand{\\K}[0]{\\mat{K}}\n",
    "\\newcommand{\\bP}[0]{\\mat{P}}\n",
    "\\newcommand{\\F}[0]{\\mat{F}}\n",
    "\\newcommand{\\bH}[0]{\\mat{H}}\n",
    "\\newcommand{\\bF}[0]{\\mat{F}}\n",
    "\\newcommand{\\R}[0]{\\mat{R}}\n",
    "\\newcommand{\\Q}[0]{\\mat{Q}}\n",
    "\\newcommand{\\B}[0]{\\mat{B}}\n",
    "\\newcommand{\\Ri}[0]{\\R^{-1}}\n",
    "\\newcommand{\\Bi}[0]{\\B^{-1}}\n",
    "\\newcommand{\\X}[0]{\\mat{X}}\n",
    "\\newcommand{\\A}[0]{\\mat{A}}\n",
    "\\newcommand{\\Y}[0]{\\mat{Y}}\n",
    "\\newcommand{\\E}[0]{\\mat{E}}\n",
    "\\newcommand{\\U}[0]{\\mat{U}}\n",
    "\\newcommand{\\V}[0]{\\mat{V}}\n",
    "%\n",
    "\\newcommand{\\x}[0]{\\bvec{x}}\n",
    "\\newcommand{\\y}[0]{\\bvec{y}}\n",
    "\\newcommand{\\bb}[0]{\\bvec{b}}\n",
    "%\n",
    "\\newcommand{\\cx}[0]{\\text{const}}\n",
    "\\newcommand{\\norm}[1]{\\|{#1}\\|}\n",
    "%\n",
    "$For any (suitably shaped matrices)\n",
    "$\\B$, $\\R$, $\\V,\\U$ such that the following exists,\n",
    "$$\\begin{align}\n",
    "    \\left( \\B^{-1} + \\V\\tr \\R^{-1} \\U \\right)^{-1}\n",
    "    =\n",
    "    \\B - \\B \\V\\tr \\left( \\R + \\U \\B \\V\\tr \\right)^{-1} \\U \\B \\, ,\n",
    "    \\tag{W}\n",
    "\\end{align}$$\n",
    "which is known as the Sherman-Morrison-Woodbury lemma/identity.\n",
    "\n",
    "The significance of this identity is that $\\U$ and $\\V$ may be rectangular matrices,\n",
    "meaning that (the necessarily square) $\\B$ and $\\R$ have different sizes.\n",
    "Thus, assuming $\\R$ is of lower rank (size) than $\\B$,\n",
    "the term $\\V\\tr \\R^{-1} \\U$ on the left-hand-side constitutes a lower-rank \"update\" (addition) to $\\B^{-1}$.\n",
    "Thus, if the inverse ($\\B$) of $\\B^{-1}$ is already known,\n",
    "computing the inverse of $\\B^{-1} + \\V\\tr \\R^{-1} \\U$\n",
    "only requires an inversion of the size of $\\R$.\n",
    "\n",
    "Prove the identity. Hint: don't derive it, just prove it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#show_answer('Woodbury')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exc 8 (Corollary 1):\n",
    "$\n",
    "%MACRO DEFINITION\n",
    "\\newcommand{\\Expect}[0]{\\mathop{}\\! \\mathbb{E}}\n",
    "\\newcommand{\\NormDist}{\\mathop{}\\! \\mathcal{N}}\n",
    "%\n",
    "\\newcommand{\\mat}[1]{{\\mathbf{{#1}}}} \n",
    "%\\newcommand{\\mat}[1]{{\\pmb{\\mathsf{#1}}}}\n",
    "\\newcommand{\\bvec}[1]{{\\mathbf{#1}}}\n",
    "%\n",
    "\\newcommand{\\trsign}{{\\mathsf{T}}}\n",
    "\\newcommand{\\tr}{^{\\trsign}}\n",
    "%\n",
    "\\newcommand{\\I}[0]{\\mat{I}}\n",
    "\\newcommand{\\K}[0]{\\mat{K}}\n",
    "\\newcommand{\\bP}[0]{\\mat{P}}\n",
    "\\newcommand{\\F}[0]{\\mat{F}}\n",
    "\\newcommand{\\bH}[0]{\\mat{H}}\n",
    "\\newcommand{\\bF}[0]{\\mat{F}}\n",
    "\\newcommand{\\R}[0]{\\mat{R}}\n",
    "\\newcommand{\\B}[0]{\\mat{B}}\n",
    "\\newcommand{\\Ri}[0]{\\R^{-1}}\n",
    "\\newcommand{\\Bi}[0]{\\B^{-1}}\n",
    "\\newcommand{\\X}[0]{\\mat{X}}\n",
    "\\newcommand{\\A}[0]{\\mat{A}}\n",
    "\\newcommand{\\Y}[0]{\\mat{Y}}\n",
    "\\newcommand{\\E}[0]{\\mat{E}}\n",
    "\\newcommand{\\U}[0]{\\mat{U}}\n",
    "\\newcommand{\\V}[0]{\\mat{V}}\n",
    "%\n",
    "\\newcommand{\\x}[0]{\\bvec{x}}\n",
    "\\newcommand{\\y}[0]{\\bvec{y}}\n",
    "\\newcommand{\\bb}[0]{\\bvec{b}}\n",
    "%\n",
    "\\newcommand{\\cx}[0]{\\text{const}}\n",
    "\\newcommand{\\norm}[1]{\\|{#1}\\|}\n",
    "%\n",
    "$Prove that, for any symmetric, positive-definite (SPD) matrices $\\R$ and $\\B$, and any matrix $\\bH$,\n",
    "$$\\begin{align}\n",
    " \t\\left(\\bH\\tr \\R^{-1} \\bH + \\B^{-1}\\right)^{-1}\n",
    "    &=\n",
    "    \\B - \\B \\bH\\tr \\left( \\R + \\bH \\B \\bH\\tr \\right)^{-1} \\bH \\B \\tag{C1}\n",
    "    \\, .\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#show_answer('Woodbury C1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exc 10 (Corollary 2):\n",
    "$\n",
    "%MACRO DEFINITION\n",
    "\\newcommand{\\Expect}[0]{\\mathop{}\\! \\mathbb{E}}\n",
    "\\newcommand{\\NormDist}{\\mathop{}\\! \\mathcal{N}}\n",
    "%\n",
    "\\newcommand{\\mat}[1]{{\\mathbf{{#1}}}} \n",
    "%\\newcommand{\\mat}[1]{{\\pmb{\\mathsf{#1}}}}\n",
    "\\newcommand{\\bvec}[1]{{\\mathbf{#1}}}\n",
    "%\n",
    "\\newcommand{\\trsign}{{\\mathsf{T}}}\n",
    "\\newcommand{\\tr}{^{\\trsign}}\n",
    "%\n",
    "\\newcommand{\\I}[0]{\\mat{I}}\n",
    "\\newcommand{\\K}[0]{\\mat{K}}\n",
    "\\newcommand{\\bP}[0]{\\mat{P}}\n",
    "\\newcommand{\\F}[0]{\\mat{F}}\n",
    "\\newcommand{\\bH}[0]{\\mat{H}}\n",
    "\\newcommand{\\bF}[0]{\\mat{F}}\n",
    "\\newcommand{\\R}[0]{\\mat{R}}\n",
    "\\newcommand{\\B}[0]{\\mat{B}}\n",
    "\\newcommand{\\Ri}[0]{\\R^{-1}}\n",
    "\\newcommand{\\Bi}[0]{\\B^{-1}}\n",
    "\\newcommand{\\X}[0]{\\mat{X}}\n",
    "\\newcommand{\\A}[0]{\\mat{A}}\n",
    "\\newcommand{\\Y}[0]{\\mat{Y}}\n",
    "\\newcommand{\\E}[0]{\\mat{E}}\n",
    "\\newcommand{\\U}[0]{\\mat{U}}\n",
    "\\newcommand{\\V}[0]{\\mat{V}}\n",
    "%\n",
    "\\newcommand{\\x}[0]{\\bvec{x}}\n",
    "\\newcommand{\\y}[0]{\\bvec{y}}\n",
    "\\newcommand{\\bb}[0]{\\bvec{b}}\n",
    "%\n",
    "\\newcommand{\\cx}[0]{\\text{const}}\n",
    "\\newcommand{\\norm}[1]{\\|{#1}\\|}\n",
    "%\n",
    "$Prove that, for the same matrices as for Corollary C1,\n",
    "$$\\begin{align}\n",
    "\t\\left(\\bH\\tr \\R^{-1} \\bH + \\B^{-1}\\right)^{-1}\\bH\\tr \\R^{-1}\n",
    "    &= \\B \\bH\\tr \\left( \\R + \\bH \\B \\bH\\tr \\right)^{-1}\n",
    "    \\tag{C2}\n",
    "    \\, .\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#show_answer('Woodbury C2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exc 12 (The \"gain\" form of the KF):\n",
    "$\n",
    "%MACRO DEFINITION\n",
    "\\newcommand{\\Expect}[0]{\\mathop{}\\! \\mathbb{E}}\n",
    "\\newcommand{\\NormDist}{\\mathop{}\\! \\mathcal{N}}\n",
    "%\n",
    "\\newcommand{\\mat}[1]{{\\mathbf{{#1}}}} \n",
    "%\\newcommand{\\mat}[1]{{\\pmb{\\mathsf{#1}}}}\n",
    "\\newcommand{\\bvec}[1]{{\\mathbf{#1}}}\n",
    "%\n",
    "\\newcommand{\\trsign}{{\\mathsf{T}}}\n",
    "\\newcommand{\\tr}{^{\\trsign}}\n",
    "%\n",
    "\\newcommand{\\I}[0]{\\mat{I}}\n",
    "\\newcommand{\\K}[0]{\\mat{K}}\n",
    "\\newcommand{\\bP}[0]{\\mat{P}}\n",
    "\\newcommand{\\F}[0]{\\mat{F}}\n",
    "\\newcommand{\\bH}[0]{\\mat{H}}\n",
    "\\newcommand{\\bF}[0]{\\mat{F}}\n",
    "\\newcommand{\\R}[0]{\\mat{R}}\n",
    "\\newcommand{\\B}[0]{\\mat{B}}\n",
    "\\newcommand{\\Ri}[0]{\\R^{-1}}\n",
    "\\newcommand{\\Bi}[0]{\\B^{-1}}\n",
    "\\newcommand{\\X}[0]{\\mat{X}}\n",
    "\\newcommand{\\A}[0]{\\mat{A}}\n",
    "\\newcommand{\\Y}[0]{\\mat{Y}}\n",
    "\\newcommand{\\E}[0]{\\mat{E}}\n",
    "\\newcommand{\\U}[0]{\\mat{U}}\n",
    "\\newcommand{\\V}[0]{\\mat{V}}\n",
    "%\n",
    "\\newcommand{\\x}[0]{\\bvec{x}}\n",
    "\\newcommand{\\y}[0]{\\bvec{y}}\n",
    "\\newcommand{\\bb}[0]{\\bvec{b}}\n",
    "%\n",
    "\\newcommand{\\cx}[0]{\\text{const}}\n",
    "\\newcommand{\\norm}[1]{\\|{#1}\\|}\n",
    "%\n",
    "$Now, let's go back to the KF, eqns (5) and (6). \n",
    "Since $\\B$ and $\\R$ are covariance matrices, they are symmetric-positive.  \n",
    "In addition, we will assume that they are full-rank, making them SPD and invertible.  \n",
    "Define the Kalman gain by:\n",
    " $$\\begin{align}\n",
    "    \\K &= \\B \\bH\\tr \\big(\\bH \\B \\bH\\tr + \\R\\big)^{-1} \\, . \\tag{K1}\n",
    "\\end{align}$$\n",
    " * (a) Apply (C1) to eqn (5) to obtain the Kalman gain form of analysis/posterior covariance matrix:\n",
    "$$\\begin{align}\n",
    "    \\bP &= [\\I_M - \\K \\bH]\\B \\, . \\tag{8}\n",
    "\\end{align}$$\n",
    "\n",
    "* (b) Apply (C2)  to (5) to abtain the identity\n",
    "$$\\begin{align}\n",
    "    \\K &= \\bP \\bH\\tr \\R  \\, . \\tag{K2}\n",
    "\\end{align}$$\n",
    "\n",
    "* (c) Show that $\\bP \\Bi = [\\I_M - \\K \\bH]$.\n",
    "* (d) Use (b) and (c) to obtain the Kalman gain form of analysis/posterior covariance\n",
    "$$\\begin{align}\n",
    "     \\hat{\\x} &= \\bb + \\K\\left[\\y - \\bH \\bb\\right] \\, . \\tag{9}\n",
    "\\end{align}$$\n",
    "\n",
    "Together, eqns (8) and (9) define the Kalman gain form of the KF update.\n",
    "The inversion (eqn 7) involved is of the size of $\\R$, while in eqn (5) it is of the size of $\\B$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In summary: \n",
    "We have derived two forms of the multivariate KF analysis update step: the \"precision matrix\" form, and the \"Kalman gain\" form. The latter is especially practical when the number of observations is smaller than the length of the state vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next: [Dynamical systems, chaos, Lorenz](T6 - Dynamical systems, chaos, Lorenz.ipynb)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
